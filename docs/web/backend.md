# 后端架构

## 架构设计和优化

### 秒杀系统为什么复杂？

1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列表、个人信息）；

2）微博系统，每个人读你关注的人的数据，一个人读多个人的数据；

3）秒杀系统，库存只有一份，所有人会在集中的时间读和写这些数据，多个人读一个数据。

例如：小米手机每周二的秒杀，可能手机只有1万部，但瞬时进入的流量可能是几百几千万。
又例如：12306抢票，票是有限的，库存一份，瞬时流量非常多，都读相同的库存。读写冲突，锁非常严重，这是秒杀业务难的地方。

参考：

[架构 秒杀系统优化思路_w3cschool](https://www.w3cschool.cn/architectroad/architectroad-optimization-of-seckilling-system.html)


### 如何优化秒杀架构？

首先了解[秒杀系统为什么复杂？](/web/backend.html#%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%8D%E6%9D%82%EF%BC%9F)

优化的方式有以下几个点。

第一层，客户端节流。

（a）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求；

（b）JS层面，限制用户在x秒之内只能提交一次请求；

这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）对于群内的高端程序员是拦不住的。firebug一抓包，http长啥样都知道，js是万万拦不住程序员写for循环，调用http接口的，这部分请求怎么处理？

第二层，后端站点层面限流。

在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。

5s只透过一个请求，其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。

页面缓存不一定要保证所有站点返回一致的页面，直接放在每个站点的内存也是可以的。优点是简单，坏处是http请求落到不同的站点，返回的车票数据可能不一样，这是站点层的请求拦截与缓存优化。

好，这个方式拦住了写for循环发http请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。

第三层，服务层拦截。

对于写请求，做**请求队列**，每次**只透有限的写请求去数据层**（下订单，支付这样的写业务）

1w部手机，只透1w个下单请求去db

3k张火车票，只透3k个下单请求去db

如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”。

对于读请求，怎么优化？**cache抗**，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。

当然，还有业务规则上的一些优化。回想12306所做的，**分时分段**售票，原来统一10点卖票，现在8点，8点半，9点，...每隔半个小时放出一批：将流量摊匀。

其次，数据粒度的优化：你去购票，对于余票查询这个业务，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票？流量大的时候，做一个**粗粒度**的“有票”“无票”缓存即可。

第三，一些**业务逻辑的异步**：例如下单业务与 支付业务的分离。这些优化都是结合 业务 来的，我之前分享过一个观点“一切脱离业务的架构设计都是耍流氓”架构的优化也要针对业务。



参考：

[架构 秒杀系统优化思路_w3cschool](https://www.w3cschool.cn/architectroad/architectroad-optimization-of-seckilling-system.html)




### 如何进行容量设计？

容量设计的场景如下：

场景一：pm要做一个很大的运营活动，技术老大杀过来，问了两个问题：


（1）机器能抗住么？

（2）如果扛不住，需要加多少台机器？


场景二：系统设计阶段，技术老大杀过来，又问了两个问题：


（1）数据库需要分库么？

（2）如果需要分库，需要分几个库？

常见的容量评估包括**数据量、并发量、带宽、CPU/MEM/DISK**等。

容量设计的步骤如下：

【步骤一：评估总访问量】

如何知道总访问量？对于一个运营活动的访问量评估，或者一个系统上线后PV的评估，有什么好的方法？

答案是：询问业务方，询问运营同学，询问产品同学，看对运营活动或者产品上线后的预期是什么。

举例：58要做一个APP-push的运营活动，计划在30分钟内完成5000w用户的push推送，预计push消息点击率10%，求push落地页系统的总访问量？

回答：5000w*10% = 500w

【步骤二：评估平均访问量QPS】

如何知道平均访问量QPS？

答案是：有了总量，除以总时间即可，如果按照天评估，一天按照4w秒计算。


举例1：push落地页系统30分钟的总访问量是500w，求平均访问量QPS

回答：500w/(30*60) = 2778，大概3000QPS


举例2：主站首页估计日均pv 8000w，求平均访问QPS

回答：一天按照4w秒算，8000w/4w=2000，大概2000QPS


提问：为什么一天按照4w秒计算？

回答：一天共24小时*60分钟*60秒=8w秒，一般假设所有请求都发生在白天，所以一般来说一天只按照4w秒评估

【步骤三：评估高峰QPS】

系统容量规划时，不能只考虑平均QPS，而是要抗住高峰的QPS，如何知道高峰QPS呢？

答案是：**根据业务特性，通过业务访问曲线**评估

举例：日均QPS为2000，业务访问趋势图如下图，求峰值QPS预估？

<img src="https://raw.githubusercontent.com/brizer/graph-bed/master/img/20200325162317.png"/>

回答：从图中可以看出，峰值QPS大概是均值QPS的2.5倍，日均QPS为2000，于是评估出峰值QPS为5000。

说明：有一些业务例如“秒杀业务”比较难画出业务访问趋势图，这类业务的容量评估不在此列。

【步骤四：评估系统、单机极限QPS】

如何评估一个业务，一个服务单机能的极限QPS呢？

答案是：压力测试

在一个服务上线前，一般来说是需要进行压力测试的（很多创业型公司，业务迭代很快的系统可能没有这一步，那就悲剧了），以APP-push运营活动落地页为例（日均QPS2000，峰值QPS5000），这个系统的架构可能是这样的：

<img src="https://raw.githubusercontent.com/brizer/graph-bed/master/img/20200325162417.png"/>


1）访问端是APP

2）运营活动H5落地页是一个web站点

3）H5落地页由缓存cache、数据库db中的数据拼装而成

通过压力测试发现，web层是瓶颈，tomcat压测单机只能抗住1200的QPS（一般来说，1%的流量到数据库，数据库500QPS还是能轻松抗住的，cache的话QPS能抗住，需要评估cache的带宽，假设不是瓶颈），我们就得到了web单机极限的QPS是1200。一般来说，线上系统是不会跑满到极限的，打个8折，单机。

线上允许跑到QPS1000。

【步骤五：根据线上冗余度回答两个问题】

好了，上述步骤1-4已经得到了峰值QPS是5000，单机QPS是1000，假设线上部署了2台服务，就能自信自如的回答技术老大提出的问题了：

（1）机器能抗住么？ -> 峰值5000，单机1000，线上2台，扛不住

（2）如果扛不住，需要加多少台机器？ ->需要额外3台，提前预留1台更好，给4台更稳

除了并发量的容量预估，数据量、带宽、CPU/MEM/DISK等评估亦可遵循类似的步骤。 






参考：

[互联网架构，如何进行容量设计？_w3cschool](https://www.w3cschool.cn/architectroad/architectroad-capacity-design.html)



### 服务器线程数究竟设置多少比较合理？

首先了解[服务线程模型](/web/backend.html#%E6%9C%8D%E5%8A%A1%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B)，这里描述的是针对IO线程与工作线程通过队列解耦类模型这个模型而言。

Web-Server通常有个配置，最大工作线程数，后端服务一般也有个配置，工作线程池的线程数量，首先了解以node为例的[libev底层的线程池原理](/language/node.html#libev%E5%BA%95%E5%B1%82%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86)。这个线程数的配置不同的业务架构师有不同的经验值，有些业务设置为CPU核数的2倍，有些业务设置为CPU核数的8倍，有些业务设置为CPU核数的32倍。

首先明白几个子问题：

提问：工作线程数是不是设置的越大越好？

回答：肯定不是的

1）一来服务器CPU核数有限，同时并发的线程数是有限的，1核CPU设置10000个工作线程没有意义

2）线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低


提问：调用sleep()函数的时候，线程是否一直占用CPU？

回答：不占用，等待时会把CPU让出来，给其他需要CPU资源的线程使用

不止调用sleep()函数，在进行一些阻塞调用，例如网络编程中的阻塞accept()【等待客户端连接】和阻塞recv()【等待下游回包】也不占用CPU资源


提问：如果CPU是单核，设置多线程有意义么，能提高并发性能么？

回答：即使是单核，使用多线程也是有意义的

1）多线程编码可以让我们的服务/代码更加清晰，有些IO线程收发包，有些Worker线程进行任务处理，有些Timeout线程进行超时检测

2）如果有一个任务一直占用CPU资源在进行计算，那么此时增加线程并不能增加并发，例如这样的一个代码：`while(1){ i++; }`

该代码一直不停的占用CPU资源进行计算，会使CPU占用率达到100%。

3）通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作。


Worker线程在执行的过程中，有一部计算时间需要占用CPU，另一部分等待时间不需要占用CPU，通过量化分析，例如打日志进行统计，可以统计出整个Worker线程执行过程中这两部分时间的比例，例如：

1）时间轴1，3，5，7【上图中粉色时间轴】的计算执行时间是100ms

2）时间轴2，4，6【上图中橙色时间轴】的等待时间也是100ms


得到的结果是，这个线程计算和等待的时间是1：1，即有50%的时间在计算（占用CPU），50%的时间在等待（不占用CPU）：

1）假设此时是单核，则设置为2个工作线程就可以把CPU充分利用起来，让CPU跑到100%

2）假设此时是N核，则设置为2N个工作现场就可以把CPU充分利用起来，让CPU跑到N*100%

结论：

N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化。

经验：

一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。

参考：

[线程数究竟设多少合理_w3cschool](https://www.w3cschool.cn/architectroad/architectroad-set-the-thread.html)




### 服务线程模型

了解常见的服务线程模型，有助于理解服务并发的原理，一般来说互联网常见的服务线程模型有如下两种：

IO线程与工作线程通过队列解耦类模型

<img src="https://raw.githubusercontent.com/brizer/graph-bed/master/img/20200325171545.png"/>

如上图，大部分Web-Server与服务框架都是使用这样的一种“IO线程与Worker线程通过队列解耦”类线程模型：

1）有少数几个IO线程监听上游发过来的请求，并进行收发包（生产者）

2）有一个或者多个任务队列，作为IO线程与Worker线程异步解耦的数据传输通道（临界资源）

3）有多个工作线程执行正真的任务（消费者）

这个线程模型应用很广，符合大部分场景，这个线程模型的特点是，工作线程内部是同步阻塞执行任务的（回想一下tomcat线程中是怎么执行Java程序的，dubbo工作线程中是怎么执行任务的），因此可以通过增加Worker线程数来增加并发能力。

纯异步线程模型

任何地方都没有阻塞，这种线程模型只需要设置很少的线程数就能够做到很高的吞吐量，Lighttpd有一种单进程单线程模式，并发处理能力很强，就是使用的的这种模型。该模型的缺点是：

1）如果使用单线程模式，难以利用多CPU多核的优势

2）程序员更习惯写同步代码，callback的方式对代码的可读性有冲击，对程序员的要求也更高

3）框架更复杂，往往需要server端收发组件，server端队列，client端收发组件，client端队列，上下文管理组件，有限状态机组件，超时管理组件的支持。


一个典型的工作线程的处理过程，从开始处理start到结束处理end，该任务的处理共有7个步骤：

<img src="https://raw.githubusercontent.com/brizer/graph-bed/master/img/20200325172936.png"/>


1）从工作队列里拿出任务，进行一些本地初始化计算，例如http协议分析、参数解析、参数校验等

2）访问cache拿一些数据

3）拿到cache里的数据后，再进行一些本地计算，这些计算和业务逻辑相关

4）通过RPC调用下游service再拿一些数据，或者让下游service去处理一些相关的任务

5）RPC调用结束后，再进行一些本地计算，怎么计算和业务逻辑相关

6）访问DB进行一些数据操作

7）操作完数据库之后做一些收尾工作，同样这些收尾工作也是本地计算，和业务逻辑相关

分析整个处理的时间轴，会发现：

1）其中1，3，5，7步骤中【上图中粉色时间轴】，线程进行本地业务逻辑计算时需要占用CPU

2）而2，4，6步骤中【上图中橙色时间轴】，访问cache、service、DB过程中线程处于一个等待结果的状态，不需要占用CPU，进一步的分解，这个“等待结果”的时间共分为三部分：

2.1）请求在网络上传输到下游的cache、service、DB

2.2）下游cache、service、DB进行任务处理

2.3）cache、service、DB将报文在网络上传回工作线程

---

### 如何优化单点系统的可用性和性能？

首先明白，**哪些情况下会存在单点系统**？
